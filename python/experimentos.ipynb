{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correr experimentos\n",
    "En este archivo está el código para correr los experimentos y escribir los resultados en archivos CSV.\n",
    "> Los archivos se guardan en la carpeta _resultados_ en formato csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación leemos los datasets en dataframes de Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función sirve para correr el código sobre una instancia ejecutando un método en particular.\n",
    "- HS1: Heuristica secuencial golosa por grado en G.\n",
    "- HS2: Heuristica secuencial golosa por grado en H.\n",
    "- HGV: Heuristica golosa por coloreo de vertices según H.\n",
    "- HS1B: Heuristica secuencial golosa con búsqueda local golosa por grado en G.\n",
    "- HS2B: Heuristica secuancial golosa con búsqueda local golosa por grado en H.\n",
    "- HGA: Heuristica golosa por coloreo de aristas según H.\n",
    "- TSS: Tabú search utilizando memoria por soluciones y vecindad con operador change y swap.\n",
    "- TSE: Tabú search utilizando memoria por estructura de solución y vecindad con operador change y swap.\n",
    "- TSSA: Tabú search utilizando memoria por soluciones y vecindad por coloreo en H. \n",
    "- TSSB: Tabú search utilizando memoria por soluciones, vecindad con operador change y swap y partiendo de una solucion inicial menos óptima.\n",
    "- TSEB:Tabú search utilizando memoria por estructura de solución, vecindad con operador change y swap y partiendo de una solucion inicial menos óptima.\n",
    "- TSSAB: Tabú search utilizando memoria por soluciones, vecindad por coloreo en H y partiendo de una solucion inicial menos óptima. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_instancia(path_instancia):\n",
    "    with open(path_instancia, \"r\") as f:\n",
    "        return f.read();\n",
    "#generamos otro dataframe con datos equitativos de la cantidad de vertices, seleccionando de forma aleatoria de los datos generados para instancias-costo\n",
    "def seleccionEquitativaDeDatos(df,k, cantV,j):\n",
    "    df_array=[];\n",
    "    df_array.append(df[df[\"cantidad_vertices\"]==10].sample(n=25))#porque tiene solo 25\n",
    "    \n",
    "    for cantVertices in range(20,cantV+1,j):\n",
    "        df_array.append(df[df[\"cantidad_vertices\"]==cantVertices].sample(n=k));\n",
    "    \n",
    "    df_instanciasRandom_costo = pd.concat(df_array).reset_index();\n",
    "    return df_instanciasRandom_costo\n",
    "\n",
    "df_peor_caso_hs1 = pd.read_csv(\"instancias/peor-caso-hs1/indice.csv\");\n",
    "df_peor_caso_hs2 = pd.read_csv(\"instancias/peor-caso-hs2/indice.csv\");\n",
    "df_mejor_caso_hs1 = pd.read_csv(\"instancias/mejor-caso-hs1/indice.csv\");\n",
    "df_mejor_caso_hs2 = pd.read_csv(\"instancias/mejor-caso-hs2/indice.csv\");\n",
    "df_instancias_calidad = pd.read_csv(\"instancias/instancias-calidad/indice.csv\");\n",
    "df_instancias_costo = pd.read_csv(\"instancias/instancias-costo/indice.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corremos los experimentos\n",
    "Vamos a guardar una tabla con las ejecuciones y sus respectivos tiempos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correr_experimento(metodo,T,pVecinos,I2,I1, archivo_instancia):\n",
    "    # Leer archivo de la instancia.\n",
    "    instancia = leer_instancia(archivo_instancia)\n",
    "    # Crear proceso para ejecutar el codigo.\n",
    "    \n",
    "    if(metodo[0]=='T'):\n",
    "        command = '../pcmi ' + '\"' + metodo + '\"' + ' ' + str(T) + ' ' + str(pVecinos) + ' ' + str(I2) + ' ' + str(I1)\n",
    "        res = (subprocess.getstatusoutput(command + ' < ' + archivo_instancia))[1].splitlines()\n",
    "        tiempo_de_ejecucion = float(res[0]);\n",
    "        impacto= int(res[1]);\n",
    "    \n",
    "    else :\n",
    "        process = subprocess.Popen([\"../pcmi\", metodo], stderr=subprocess.PIPE, stdout=subprocess.PIPE, stdin=subprocess.PIPE, universal_newlines = True)\n",
    "        # Poner la instancia en la entrada estandar.\n",
    "        process.stdin.write(instancia)\n",
    "        process.stdin.flush()\n",
    "        # Correr experimento.\n",
    "        exit_code = process.wait();\n",
    "        # Verificar que el proceso no fallo.\n",
    "        if (exit_code != 0): raise(F\"Hubo un error en la experimentacion para el algoritmo: {metodo} con la instancia {archivo_instancia}.\")\n",
    "        # Leer salida de STDERR con los tiempos de ejecucion de cada metodo.\n",
    "        tiempo_de_ejecucion = float(process.stderr.read());\n",
    "        impacto = int(process.stdout.read().split('\\n')[0]);\n",
    "\n",
    "        process.stdin.close();\n",
    "        process.stdout.close();\n",
    "        process.stderr.close();\n",
    "    \n",
    "    return [tiempo_de_ejecucion,impacto];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentos = [];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 1: Complejidad y calidad de Heuristicas secuenciales\n",
    "\n",
    "Correr la Heuristica secuencial en sus variantes HS1 y HS2 en sus primeras [A DEFINIR] instancias con sus peores casos respectivamente e instancias generadas aleatoriamente para medir sus costos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionamos los datos de manera equitativa por cantidad de vertices\n",
    "df_instanciasRandom_costo = seleccionEquitativaDeDatos(df_instancias_costo,2,110,2);\n",
    "\n",
    "for n in range(0, df_peor_caso_hs1.shape[0]):    \n",
    "    fila_n = df_peor_caso_hs1.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"HS1\",fila_n[\"archivo\"]]);\n",
    "\n",
    "for n in range(0, df_mejor_caso_hs1.shape[0]):    \n",
    "    fila_n = df_mejor_caso_hs1.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"HS1\",fila_n[\"archivo\"]]);    \n",
    "\n",
    "for n in range(0, df_instanciasRandom_costo.shape[0]):\n",
    "    fila_n = df_instanciasRandom_costo.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"HS1\",fila_n[\"archivo\"]]);\n",
    "\n",
    "for n in range(0, df_peor_caso_hs2.shape[0]):   \n",
    "    fila_n = df_peor_caso_hs2.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"HS2\",fila_n[\"archivo\"]]);\n",
    "\n",
    "for n in range(0, df_mejor_caso_hs2.shape[0]):    \n",
    "    fila_n = df_mejor_caso_hs2.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"HS2\",fila_n[\"archivo\"]]);    \n",
    "\n",
    "for n in range(0, df_instanciasRandom_costo.shape[0]):\n",
    "    fila_n = df_instanciasRandom_costo.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"HS2\",fila_n[\"archivo\"]]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 2 : Complejidad y calidad de Heuristica golosa de coloreo según H\n",
    "Correr HGV para su peor caso y para las instancias generadas aleatoriamente para medir los costos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionamos los datos de manera equitativa por cantidad de vertices\n",
    "df_instanciasRandom_costo = seleccionEquitativaDeDatos(df_instancias_costo,1,110,2);\n",
    "\n",
    "for n in range(0, df_instanciasRandom_costo.shape[0]):\n",
    "    fila_n = df_instanciasRandom_costo.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"HGV\",fila_n[\"archivo\"]]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 3 : Impacto del método utilizado para generar vecinos en Tabú search\n",
    "Correr TSS y TSSA para las instancias de calidad y costo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionamos los datos de manera equitativa por cantidad de vertices\n",
    "df_instanciasRandom_costo = seleccionEquitativaDeDatos(df_instancias_costo,5,60,2);\n",
    "\n",
    "for n in range(0, df_instancias_calidad.shape[0]):\n",
    "    fila_n = df_instancias_calidad.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSS\", 1000, 30, 100, 1000,fila_n[\"archivo\"]]);\n",
    "\n",
    "for n in range(0, df_instanciasRandom_costo.shape[0]):\n",
    "    fila_n = df_instanciasRandom_costo.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSS\", 1000, 30, 100, 1000,fila_n[\"archivo\"]]);\n",
    "\n",
    "for n in range(0, df_instancias_calidad.shape[0]):\n",
    "    fila_n = df_instancias_calidad.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSSA\", 1000, 30, 100, 1000,fila_n[\"archivo\"]]);\n",
    "\n",
    "for n in range(0, df_instanciasRandom_costo.shape[0]):\n",
    "    fila_n = df_instanciasRandom_costo.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSSA\", 1000, 30, 100, 1000,fila_n[\"archivo\"]]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 4: Impacto de la solución inicial en Tabú search\n",
    "Correr TSSB y TSSAB para las instancias de csoto y calidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionamos los datos de manera equitativa por cantidad de vertices\n",
    "df_instanciasRandom_costo = seleccionEquitativaDeDatos(df_instancias_costo,5,60,2);\n",
    "\n",
    "for n in range(0, df_instancias_calidad.shape[0]):\n",
    "    fila_n = df_instancias_calidad.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSSAB\", 1000, 30, 100, 1000,fila_n[\"archivo\"]]);\n",
    "\n",
    "for n in range(0, df_instanciasRandom_costo.shape[0]):\n",
    "    fila_n = df_instanciasRandom_costo.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSSAB\", 1000, 30, 100, 1000,fila_n[\"archivo\"]]);\n",
    "\n",
    "for n in range(0, df_instancias_calidad.shape[0]):\n",
    "    fila_n = df_instancias_calidad.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSSB\", 1000, 30, 100, 1000,fila_n[\"archivo\"]]);\n",
    "\n",
    "for n in range(0, df_instanciasRandom_costo.shape[0]):\n",
    "    fila_n = df_instanciasRandom_costo.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSSB\", 1000, 30, 100, 1000,fila_n[\"archivo\"]]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 5 : Impacto del tipo de memoria utilizada en Tabú search\n",
    "Correr TSE para las instancias de costo y calidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionamos los datos de manera equitativa por cantidad de vertices\n",
    "df_instanciasRandom_costo = seleccionEquitativaDeDatos(df_instancias_costo,5,60,2);\n",
    "\n",
    "for n in range(0, df_instancias_calidad.shape[0]):\n",
    "    fila_n = df_instancias_calidad.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSE\", 1000, 30, 100, 1000,fila_n[\"archivo\"]]);\n",
    "\n",
    "for n in range(0, df_instanciasRandom_costo.shape[0]):\n",
    "    fila_n = df_instanciasRandom_costo.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSE\", 1000, 30, 100, 1000,fila_n[\"archivo\"]]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 6 : Configuración de los parametros de Tabú search\n",
    "Correr TSS, TSE y TSSA para las instancias de costo variando sus parametros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionamos los datos de manera equitativa por cantidad de vertices\n",
    "df_instanciasRandom_costo = seleccionEquitativaDeDatos(df_instancias_costo,1,30,2);\n",
    "\n",
    "for n in range(0, df_instanciasRandom_costo.shape[0]):\n",
    "    for t in range(100, 6101,1000):\n",
    "        for p in range(10, 101, 20):\n",
    "            fila_n = df_instanciasRandom_costo.iloc[n];\n",
    "            experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSS\", t, p, 500, 1000,fila_n[\"archivo\"]]);\n",
    "            experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSSA\", t, p, 500, 1000,fila_n[\"archivo\"]]);\n",
    "\n",
    "for n in range(0, df_instanciasRandom_costo.shape[0]):\n",
    "    for itsm in range(0,1001,200):\n",
    "        for it in range(0,5001,1000):\n",
    "            fila_n = df_instanciasRandom_costo.iloc[n];\n",
    "            experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSS\", 1000, 30, itsm, it,fila_n[\"archivo\"]]);\n",
    "            experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSSA\", 1000, 30, itsm, it,fila_n[\"archivo\"]]);\n",
    "\n",
    "for n in range(0, df_instancias_calidad.shape[0]):\n",
    "    for t in range(100, 6101,1000):\n",
    "        for p in range(10, 101, 20):\n",
    "            fila_n = df_instancias_calidad.iloc[n];\n",
    "            experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSS\", t, p, 500, 1000,fila_n[\"archivo\"]]);\n",
    "            experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSSA\", t, p, 500, 1000,fila_n[\"archivo\"]]);\n",
    "\n",
    "for n in range(0, df_instancias_calidad.shape[0]):\n",
    "    for itsm in range(0,1001,200):\n",
    "        for it in range(0,5001,1000):\n",
    "            fila_n = df_instancias_calidad.iloc[n];\n",
    "            experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSS\", 1000, 30, itsm, it,fila_n[\"archivo\"]]);\n",
    "            experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSSA\", 1000, 30, itsm, it,fila_n[\"archivo\"]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 7 : Contraste entre los distintos métodos para resolver el problema\n",
    "Correr TSS, TSE y TSSA para contrastar con los demás métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionamos los datos de manera equitativa por cantidad de vertices\n",
    "df_instanciasRandom_costo = seleccionEquitativaDeDatos(df_instancias_costo,5,60,2);\n",
    "\n",
    "#cuando averiguemos la mejor configuracion hay que ponerla en este exp\n",
    "for n in range(0, df_instancias_calidad.shape[0]):\n",
    "    fila_n = df_instancias_calidad.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSS\",2000,30,100,2500,fila_n[\"archivo\"]]);\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSE\",2000,30,100,2500,fila_n[\"archivo\"]]);\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSSA\",2000,30,100,2500,fila_n[\"archivo\"]]);\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"HS1\",fila_n[\"archivo\"]]);\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"HS2\",fila_n[\"archivo\"]]);\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"HGV\",fila_n[\"archivo\"]]);\n",
    "\n",
    "for n in range(0, df_instanciasRandom_costo.shape[0]):\n",
    "    fila_n = df_instanciasRandom_costo.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSS\",2000,30,100,2500,fila_n[\"archivo\"]]);\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSE\",2000,30,100,2500,fila_n[\"archivo\"]]);\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"TSSA\",2000,30,100,2500,fila_n[\"archivo\"]]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 8 : Contraste  entre búsqueda local golosa y tabú search \n",
    "Correr HS1B y HS2B sobre las instancias de costo y calidad para contrastar con TSSB y TSSAB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionamos los datos de manera equitativa por cantidad de vertices\n",
    "df_instanciasRandom_costo = seleccionEquitativaDeDatos(df_instancias_costo,5,60,2);\n",
    "\n",
    "for n in range(0, df_instancias_calidad.shape[0]):\n",
    "    fila_n = df_instancias_calidad.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"HS1B\",fila_n[\"archivo\"]]);\n",
    "\n",
    "for n in range(0, df_instanciasRandom_costo.shape[0]):\n",
    "    fila_n = df_instanciasRandom_costo.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"HS1B\",fila_n[\"archivo\"]]);\n",
    "\n",
    "for n in range(0, df_instancias_calidad.shape[0]):\n",
    "    fila_n = df_instancias_calidad.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"HS2B\",fila_n[\"archivo\"]]);\n",
    "\n",
    "for n in range(0, df_instanciasRandom_costo.shape[0]):\n",
    "    fila_n = df_instanciasRandom_costo.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"cantidad_vertices\"], fila_n[\"impacto_esperado\"], \"HS2B\",fila_n[\"archivo\"]]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutar los experimentos y guardar los resultados en un archivo CSV.\n",
    "Este paso puede tardar unos minutos hasta terminar de ejecutarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Experimento: 6248/6248'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columnas = [\"dataset\", \"cantidad_vertices\", \"impacto_esperado\",\"impacto_obtenido\",\"gap\",\"metodo\",\"tamano_memoria\",\"%_de_vecindad\",\"iteraciones_sin_mejora\",\"iteraciones\", \"tiempo\"];\n",
    "filas = [];\n",
    "numero = 1\n",
    "T = 5 # Numero de veces que se ejecuta cada experimento (para mayor fidelidad del tiempo).\n",
    "for experimento in experimentos:\n",
    "    # Voy mostrando que experimento se esta ejecutando.\n",
    "    clear_output(wait=True)\n",
    "    display('Experimento: ' + str(numero) + \"/\" + str(len(experimentos)))\n",
    "    numero += 1\n",
    "    \n",
    "    # Ejecutamos el experimento T veces y obtenemos la mediana del impacto y de los tiempos.\n",
    "    tiempos = []\n",
    "    impactos = []\n",
    "    gaps = []\n",
    "    for i in range(0, T):\n",
    "        if(experimento[3][0]=='T'):\n",
    "            res = correr_experimento(experimento[3], experimento[4], experimento[5], experimento[6], experimento[7], experimento[8]);\n",
    "            impactos.append(res[1]);\n",
    "            if(int(experimento[2])!=0):\n",
    "                gaps.append(100 - res[1]*100/int(experimento[2]));#dada la randomizacion tomamos la mediana de los gaps en los metodos de tabu\n",
    "            else:\n",
    "                gaps.append(0);\n",
    "        else:\n",
    "            res= correr_experimento(experimento[3],-1,-1,-1,-1, experimento[4]);\n",
    "            impactos = [res[1]];\n",
    "            if(int(experimento[2])!=0):\n",
    "                gaps = 100 - res[1]*100/int(experimento[2]);# como no va a variar el impacto en los secuenciales \n",
    "            else:\n",
    "                gaps = 0 #sabemos que nuestro algoritmo no va a dar más porque tenemos un verificador de que el coloreo sea valido, \n",
    "                         #al ser el impacto esperado cero entonces, no es posible dar más que eso por lo tanto nuestra validacion va a activarse\n",
    "            \n",
    "        tiempos.append(res[0]);\n",
    "        \n",
    "    tiempo = np.median(tiempos);\n",
    "    impacto = np.median(impactos);\n",
    "    gap = np.median(gaps);\n",
    "    if(experimento[3][0]=='T'):\n",
    "        filas.append([experimento[0], experimento[1], experimento[2],impacto,gap,experimento[3], experimento[4], experimento[5], experimento[6], experimento[7],tiempo]);\n",
    "    else:\n",
    "        filas.append([experimento[0], experimento[1], experimento[2],impacto,gap,experimento[3],'-','-','-','-', tiempo]);\n",
    "df_resultado = pd.DataFrame(filas, columns=columnas);\n",
    "df_resultado.to_csv(\"resultados/resultados.csv\", index=False, header=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6248"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(experimentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
