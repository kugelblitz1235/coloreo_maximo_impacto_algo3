{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generador de instancias\n",
    "En este notebook está el código para generar los sets de instancias que se usan para experimentar.\n",
    "- Estas instancias van a ser guardadas en la carpeta __instancias__.\n",
    "- Cada set estará en su propia carpeta y tendrá un archivo _indice.csv_ que contendrá información sobre las instancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_instance(dataset, instance_name, n, G, H):\n",
    "    with open(F\"instancias/{dataset}/{instance_name}.txt\", \"w\") as f:\n",
    "        print(n, len(G),len(H),file=f)\n",
    "        for aristaG in G: \n",
    "            print(str(aristaG[0])+\" \"+str(aristaG[1]), file=f, end=\"\\n\")\n",
    "        for aristaH in H: \n",
    "            print(str(aristaH[0])+\" \"+str(aristaH[1]), file=f, end=\"\\n\")\n",
    "\n",
    "def save_index(dataset, instances):\n",
    "    with open(F\"instancias/{dataset}/instances.txt\", \"w\") as f:\n",
    "        for instance in instances: \n",
    "            print(instance, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-3-5c330d08deda>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-5c330d08deda>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    acum = acum + (l1[i] - l2[i])** 2\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def diff(l1, l2):\n",
    "    dif = [i for i in l1 if i not in l2]\n",
    "    return dif\n",
    "\n",
    "def distEucli(l1, l2):\n",
    "    acum = 0\n",
    "    for i  in range(0, len(l1)):\n",
    "    acum = acum + (l1[i] - l2[i])** 2\n",
    "    acum = acum**(1/2)\n",
    "    return acum\n",
    "\n",
    "def enlazar(n,caristas):\n",
    "    vec = []\n",
    "\tfor i in range(int(caristas)):\n",
    "\t\testaEn = True\n",
    "\t\twhile estaEn:\n",
    "\t\t\tmismos = True\n",
    "\t\t\twhile mismos:\n",
    "                a = randrange(1, int(n)+1)\n",
    "                b = randrange(1, int(n)+1)\n",
    "                if a != b:\n",
    "                    mismos = False\n",
    "                if a < b:\n",
    "                    par = (a,b)\n",
    "                else:\n",
    "                    par = (b,a)\n",
    "                if par not in vec:\n",
    "                    estaEn = False \n",
    "        vec = vec + [par]\n",
    "        \n",
    "\treturn vec\n",
    "\n",
    "def generar(n,caristasg,caristash):\n",
    "\th = enlazar(n,caristash)\n",
    "\tg = enlazar(n,caristasg)\n",
    "\n",
    "\tarchivo = open('in' + n + '.in','w')\n",
    "\tarchivo.write(n + \" \" + caristasg + \" \" + caristash + \"\\n\")\n",
    "\n",
    "\tfor par in g:\n",
    "\t\tarchivo.write(str(par[0]) + \" \" + str(par[1]) + \"\\n\")\n",
    "\tfor par in h:\n",
    "\t\tarchivo.write(str(par[0]) + \" \" + str(par[1]) + \"\\n\")\n",
    "\n",
    "\tarchivo.close()\n",
    "\n",
    "def peorcasoh3(n, caristash):\n",
    "\th = enlazar(n, caristash)\n",
    "\tady = []\n",
    "\tg = []\n",
    "\tfor i in range(int(n)+1):\n",
    "\t\tady = ady + [[]]\n",
    "\t\tprint(i + 1)\t\n",
    "\t#print(ady)\n",
    "\tfor p in h:\n",
    "\t\t#print(p)\n",
    "\t\tady[p[0]] = ady[p[0]] + [p]\n",
    "\t\tady[p[1]] = ady[p[1]] + [p]\n",
    "\t#print(ady)\n",
    "\t#ady.sort(key=len, reverse=True)\n",
    "\tprint(ady)\n",
    "\tprint(\"------------\")\n",
    "\tfor i in range(1, int(n)+1):\n",
    "\t\tprint (str(i) + \" = \" + str(ady[i]))\n",
    "\t\tif len(ady[i]) > 0:\n",
    "\t\t\tj = i - 1\n",
    "\t\t\tif j < 1:\n",
    "\t\t\t\tj = int(n)\n",
    "\t\t\tfor elem in ady[i]:\n",
    "\t\t\t\tif elem[0] == i:\n",
    "\t\t\t\t\telem = (j, elem[1])\n",
    "\t\t\t\telif elem[1] == i:\n",
    "\t\t\t\t\telem == (elem[0], j)\n",
    "\t\t\t\tif elem not in g and elem[0] != elem[1]:\n",
    "\t\t\t\t\tg = g + [elem]\n",
    "\tprint (g)\n",
    "\n",
    "\tarchivo = open('in' + n + '.in','w')\n",
    "\tarchivo.write(n + \" \" + str(len(g)) + \" \" + str(len(h)) + \"\\n\")\n",
    "\n",
    "\tfor par in g:\n",
    "\t\tarchivo.write(str(par[0]) + \" \" + str(par[1]) + \"\\n\")\n",
    "\tfor par in h:\n",
    "\t\tarchivo.write(str(par[0]) + \" \" + str(par[1]) + \"\\n\")\n",
    "\n",
    "\tarchivo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1\n",
    "Instancias generadas para el peor caso en cuanto a impacto de la primer heuristica golosa constructiva que se basa en el coloreo secuencial de los vertices, la generación de las mismas está descripta en el informe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "filas_indice = []\n",
    "for cantidad_vertices in range(10, 500):\n",
    "    for caristasG in range(math.floor(cantidad_vertices/2),math.floor(cantidad_vertices*(cantidad_vertices-1)/2)-cantidad_vertices)\n",
    "        h = []\n",
    "        g = enlazar(cantidad_vertices,caristasg) #[(v,w)..]\n",
    "        orden = #lista de los vertices ordenados por adyacencia según grado en G\n",
    "        for i in range(int(int(cantidad_vertices)/2)):\n",
    "            print(i+1)\n",
    "            a = i + 1\n",
    "            b = i + int(int(cantidad_vertices)/2) + 1\n",
    "            par = (a,b)\n",
    "            h = h + [par]\n",
    "        impacto_esperado = diff(g,h)\n",
    "        save_instance(\"peor-caso-hs1\", F\"HS1-AG{caristasG}-PC-{cantidad_vertices}\",cantidad_vertices,G,H)\n",
    "        filas_indice.append([\"peor-caso-hs1\", F\"HS1-AG{caristasG}-PC-{cantidad_vertices}\", cantidad_vertices, impacto_esperado, F\"instancias/peor-caso-hs1/HS1-AG{caristasG}-PC-{cantidad_vertices}.txt\"])\n",
    "pd.DataFrame(filas_indice, columns=[\"dataset\", \"instancia\", \"cantidad_vertices\", \"impacto_esperado\", \"archivo\"]).to_csv(\"instancias/peor-caso-hs1/indice.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2\n",
    "Instancias generadas para el mejor caso para la calidad de la primer heuristica golosa constructiva que se basa en el coloreo secuencial de los vertices, la generación de las mismas está descripta en el informe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filas_indice = []\n",
    "for cantidad_vertices in range(10, 500):\n",
    "    for caristasG in range(math.floor(cantidad_vertices/2),math.floor(cantidad_vertices*(cantidad_vertices-1)/2)-cantidad_vertices)\n",
    "        h = []\n",
    "        g =  enlazar(n,caristasg)\n",
    "        orden = #orden de evaluacion de las aristas\n",
    "        for i in range(int(n)):\n",
    "            a = i + 1\n",
    "            b = i + 2\n",
    "            par = (a,b)\n",
    "            h = h + [par]\n",
    "        impacto_esperado = diff(g,h)\n",
    "        save_instance(\"mejor-caso-hs1\", F\"HS1-AG{caristasG}-MC-{cantidad_vertices}\",cantidad_vertices,G,H)\n",
    "        filas_indice.append([\"mejor-caso-hs1\", F\"HS1-AG{caristasG}-MC-{cantidad_vertices}\", cantidad_vertices, impacto_esperado, F\"instancias/mejor-caso-hs1/HS1-AG{caristasG}-MC-{cantidad_vertices}.txt\"])\n",
    "pd.DataFrame(filas_indice, columns=[\"dataset\", \"instancia\", \"cantidad_vertices\", \"impacto_esperado\", \"archivo\"]).to_csv(\"instancias/mejor-caso-hs1/indice.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 3\n",
    "Instancias de peor caso con respecto al impacto obtenido para la segunda heuristica golosa constructiva secuencial, están descriptas en el informe en más detalle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "filas_indice = []\n",
    "for cantidad_vertices in range(10, 500):\n",
    "    for caristasH in range(math.floor(cantidad_vertices/2),math.floor(cantidad_vertices*(cantidad_vertices-1)/2)-cantidad_vertices)\n",
    "        h = enlazar(n,caristash)\n",
    "        g = []\n",
    "        for i in range(int(n)):\n",
    "        a = i + 1 \n",
    "        b = i + 2\n",
    "        par = (a,b)\n",
    "        if par in g :\n",
    "            estaEn = True\n",
    "        while estaEn:\n",
    "            b = b + 1\n",
    "            par = (a, b)\n",
    "            if par not in h:\n",
    "                estaEn = False \n",
    "        g = g + [par]\n",
    "    impacto_esperado = diff(g,h) #utilizamos una cota superior para el impacto optimo\n",
    "    save_instance(\"peor-caso-hs2\", F\"HS2--AH{caristasH}-PC-{cantidad_vertices}\",cantidad_vertices,G,H)\n",
    "    filas_indice.append([\"peor-caso-hs2\", F\"HS2-AH{caristasH}-PC-{cantidad_vertices}\", cantidad_vertices, impacto_esperado, F\"instancias/peor-caso-hs2/HS2-AH{caristasH}-PC-{cantidad_vertices}.txt\"])\n",
    "pd.DataFrame(filas_indice, columns=[\"dataset\", \"instancia\", \"cantidad_vertices\", \"impacto_esperado\", \"archivo\"]).to_csv(\"instancias/peor-caso-hs2/indice.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 4\n",
    "Instancias de mejor caso de calidad para la segunda heuristica constructiva golosa, están descriptas en el informe en más detalle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filas_indice = []\n",
    "for cantidad_vertices in range(10, 500):\n",
    "    for caristasH in range(math.floor(cantidad_vertices/2),math.floor(cantidad_vertices*(cantidad_vertices-1)/2)-cantidad_vertices)\n",
    "        h = enlazar(n, caristash)\n",
    "        g = []\n",
    "        for i in range(int(int(n)/2)):\n",
    "            print(i+1)\n",
    "            a = i + 1\n",
    "            b = i + int(int(n)/2) + 1\n",
    "            par = (a,b)\n",
    "            g = g + [par]\n",
    "    impacto_esperado = diff(g,h) #utilizamos una cota superior para el impacto optimo\n",
    "    save_instance(\"mejor-caso-hs2\", F\"HS2-AH{caristasH}-MC-{cantidad_vertices}\",cantidad_vertices,G,H)\n",
    "    filas_indice.append([\"mejor-caso-hs2\", F\"HS2-AH{caristasH}-MC-{cantidad_vertices}\", cantidad_vertices, impacto_esperado, F\"instancias/mejor-caso-hs2/HS2-AH{caristasH}-PC-{cantidad_vertices}.txt\"])\n",
    "pd.DataFrame(filas_indice, columns=[\"dataset\", \"instancia\", \"cantidad_vertices\", \"impacto_esperado\", \"archivo\"]).to_csv(\"instancias/mejor-caso-hs2/indice.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 5\n",
    "Instancias con el peor caso de calidad para la heurística golosa constructiva basada en el coloreo de G a partir de los vertices de H, estás instancias serán más detalladas en el informe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filas_indice = []\n",
    "for cantidad_vertices in range(10, 500):\n",
    "    for caristasH in range(math.floor(cantidad_vertices/2),math.floor(cantidad_vertices*(cantidad_vertices-1)/2)-cantidad_vertices)\n",
    "        #PEGAR CODIGO PARA GENERAR EL PEOR CASO\n",
    "    impacto_esperado = diff(g,h) #utilizamos una cota superior para el impacto optimo\n",
    "    save_instance(\"peor-caso-hgv\", F\"HGV-AH{caristasH}-PC-{cantidad_vertices}\",cantidad_vertices,G,H)\n",
    "    filas_indice.append([\"peor-caso-hgv\", F\"HGV-AH{caristasH}-PC-{cantidad_vertices}\", cantidad_vertices, impacto_esperado, F\"instancias/pero-caso-hgv/HGV-AH{caristasH}-PC-{cantidad_vertices}.txt\"])\n",
    "pd.DataFrame(filas_indice, columns=[\"dataset\", \"instancia\", \"cantidad_vertices\", \"impacto_esperado\", \"archivo\"]).to_csv(\"instancias/peor-caso-hgv/indice.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 6\n",
    "Instancias generadas de forma aleatoria para una gran aplitud de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filas_indice = []\n",
    "for cantidad_vertices in range(10, 500):\n",
    "    for caristasH in range(math.floor(cantidad_vertices/2),math.floor(cantidad_vertices*(cantidad_vertices-1)/2)-cantidad_vertices)\n",
    "        for caristasG in range(math.floor(cantidad_vertices/2),math.floor(cantidad_vertices*(cantidad_vertices-1)/2)-cantidad_vertices)\n",
    "            #generar aleatorios\n",
    "    \n",
    "    impacto_esperado = diff(g,h) #utilizamos una cota superior para el impacto optimo\n",
    "    save_instance(\"instancias-costo\", F\"IC-{cantidad_vertices}\",cantidad_vertices,G,H)\n",
    "    filas_indice.append([\"instancias-costo\", F\"HS2-PC-{cantidad_vertices}\", cantidad_vertices, impacto_esperado, F\"instancias/pero-caso-hs2/HS2-PC-{cantidad_vertices}.txt\"])\n",
    "pd.DataFrame(filas_indice, columns=[\"dataset\", \"instancia\", \"cantidad_vertices\", \"impacto_esperado\", \"archivo\"]).to_csv(\"instancias/peor-caso-hs2/indice.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 6\n",
    "Instancias provistas por la catedra para la medición de calidad de nuestro algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solamente generamos el indice, dado que las instancias ya nos fueron provistas por la catedra\n",
    "filas_indice = []\n",
    "filas_indice.append([\"instancias-calidad\", F\"CMI-n6\", 6, 1, F\"instancias/instancias-calidad/CMI-n6.in\"])\n",
    "filas_indice.append([\"instancias-calidad\", F\"CMI-n8\", 8, 6, F\"instancias/instancias-calidad/CMI-n8.in\"])\n",
    "filas_indice.append([\"instancias-calidad\", F\"CMI-n10\", 10, 3, F\"instancias/instancias-calidad/CMI-n10.in\"])\n",
    "filas_indice.append([\"instancias-calidad\", F\"CMI-n12\", 12, 16, F\"instancias/instancias-calidad/CMI-n12.in\"])\n",
    "filas_indice.append([\"instancias-calidad\", F\"CMI-n14\", 14, 12, F\"instancias/instancias-calidad/CMI-n14.in\"])\n",
    "filas_indice.append([\"instancias-calidad\", F\"CMI-n16\", 16, 20, F\"instancias/instancias-calidad/CMI-n16.in\"])\n",
    "filas_indice.append([\"instancias-calidad\", F\"CMI-n18\", 18, 27, F\"instancias/instancias-calidad/CMI-n18.in\"])\n",
    "filas_indice.append([\"instancias-calidad\", F\"CMI-n20\", 20, 25, F\"instancias/instancias-calidad/CMI-n20.in\"])\n",
    "filas_indice.append([\"instancias-calidad\", F\"CMI-n22\", 22, 26, F\"instancias/instancias-calidad/CMI-n22.in\"])\n",
    "filas_indice.append([\"instancias-calidad\", F\"CMI-n24\", 24, 33, F\"instancias/instancias-calidad/CMI-n24.in\"])\n",
    "filas_indice.append([\"instancias-calidad\", F\"CMI-n26\", 26, 38, F\"instancias/instancias-calidad/CMI-n26.in\"])\n",
    "filas_indice.append([\"instancias-calidad\", F\"CMI-n28\", 28, 48, F\"instancias/instancias-calidad/CMI-n28.in\"])\n",
    "filas_indice.append([\"instancias-calidad\", F\"CMI-n30\", 30, 47, F\"instancias/instancias-calidad/CMI-n30.in\"])\n",
    "pd.DataFrame(filas_indice, columns=[\"dataset\", \"instancia\", \"cantidad_vertices\", \"impacto_esperado\", \"archivo\"]).to_csv(\"instancias/instancias-calidad/indice.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
